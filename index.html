<!DOCTYPE HTML>
<html>

<head>
    <title>Ansh Shah</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1000">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel="stylesheet" -->
    <link rel="stylesheet" href="style.css" />

    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'G-P4QQ9215TN', 'auto');
        ga('send', 'pageview');
    </script>
    <style>
        /* Styling for the construction banner */
        #construction-banner {
            background-color: #d388187c;
            color: #333;
            padding: 10px;
            text-align: center;
            font-size: 20px;
            font-weight: bold;
        }
    </style>
</head>

<body id="body">
    <!-- <div id="construction-banner">
        This website was last updated on 15th December 2024. <br>
    </div> -->
    <div id="main">
        <!-- <header id="header">
                <a href="index.html">HOME</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
                <a href="">LAB</a>
                <br>
            </header> -->
        <header id="header">
            <a href="index.html">HOME</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
            <a href="blog.html">BLOG LIST</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
            <a href="reading_list.html">PAPERS LIST</a>
        </header>
        <!-- <header id="header">
                <a href="index.html">HOME</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
                <a href="blog.html">BLOG</a>
            </header> -->
        <div id="profile">
            <div id="profile-pic">
                <img src="data/people/ansh.jpg">
                <p>
                    <a
                        href="https://drive.google.com/file/d/1vq92ZgxZbEXoTaQXjzux3Wr7ASmcZhT8/view?usp=sharing">Resume</a>
                    &nbsp;/&nbsp;
                    <!-- <a href="https://scholar.google.com/citations?user=G7bxqvMAAAAJ&hl=en">Scholar</a>&nbsp;/&nbsp; -->
                    <a href="https://twitter.com/baymax3009">Twitter</a>
                    &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/anshshah3009/">LinkedIn</a>
                </p>
            </div>
            <div id="profile-intro">
                <div id="profile-name">Ansh Shah</div>
                <p>

                    Currently I am a care-free learner collaborating with research groups on interesting topics. Previously I was a research assistant at the <a href="https://robotics.iiit.ac.in/">Robotics Research
                        Center (RRC)</a> , IIIT Hyderabad, under the
                    guidance of <a href="https://scholar.google.co.in/citations?user=QDuPGHwAAAAJ">Prof Madhava
                        Krishna</a> . My interest lies in the field of <b>Robot Learning</b> and <b>3D Vision</b>.
                    <!-- My research interest revolves around improving the generalizability of robot <a>motion policies</a> and <a>decision-making</a> AI agents. I broadly 
                        focus on enhancing the <a>adaptability of learned policies</a> through environment dynamics or learned 
                        environment models. For example, demonstrating skills like holding a cup of tea, pushing a book, folding clothes, 
                        or simply avoiding collisions requires training data specific to each skill.<br><br>  -->

                    <!-- improving the <a>generalizability of AI and robot systems</a>. -->
                </p>
                <p>
                    I graduated from <a href="https://www.bits-pilani.ac.in/pilani">BITS Pilani</a> in 2023 with an
                    M.Sc. in
                    Physics and a B.E. in Mechanical Engineering. I joined RRC, IIIT Hyderabad for my Bachelor's
                    Thesis, where now I am continuing as a Research Assistant. I was also fortunate to have
                    opportunities to collaborate with Prof Arun Kumar Singh (University of Tartu, Estonia), during my time at IIIT Hyderabad.
                </p>
                <br>
                <br>
                <h1>Research Interests & Ideas</h1>
                <p>My research interests focus on the trio of action, perception, and cognition, where I aim to build machines that can perceive and understand the real world, recognize the physical consequences of their actions, and explore novel behaviors to achieve complex goals. I am especially driven by the challenge of creating embodiment-aware generalist agents that can adapt to new tasks without task-specific training data. I believe that while high-level reasoning can often be abstracted or mimicked effectively, the true challenge lies in developing robust low-level control. Contrary to the common approach of learning low-level manipulation through imitation of human-teleoperated demonstrations or skill transfer from videos, I argue that robots should learn low-level control by acquiring state-based local policies using reinforcement learning, which allows them to explore and understand their own capabilities.

                    A few fundamental question in the field of robot learning that I am interested in are:
                    <a>1.</a> At what level in the TAMP hierarchy should we build robust representations for embodiment
                    generalisation?
                    <a>2.</a> How can we learn to control robots in a data efficient manner?
                    <a>3.</a> Can learning a grounded 3D scene representation help in learning better policies?

                    <!-- I believe that there is a lot to be explored in the field of colloborative RL, like the task of dual
                    arm manipulation where the robot has to learn to use both arms to manipulate the same object
                    together. Understanding of Physics cannot is difficult to design into rewards and we need to explore
                    the idea of learning physics in an unsupervied fashion. -->


                    <!-- I believe that high level cognition <a
                        href="https://en.wikipedia.org/wiki/Moravec%27s_paradox">Moravec's Paradox</a>â€”I believe that
                    robots can not only mimic human abilities but eventually <a
                        href="https://medium.com/codex/lee-sedol-vs-alphago-how-googles-a-i-machine-beat-the-18-times-world-go-champion-214ffae72fbd">out-perform
                        them</a> in performing intricate real-world tasks. Through my work, I aim to push the boundaries
                    of robot learning, building systems that learn from experience and generalize across diverse
                    environments.</p> -->


                    <!-- My research interest revolves around the <a
                    href="https://en.wikipedia.org/wiki/Moravec%27s_paradox">robot learning</a> problem.
                My goal is to create generalist agents that learn from prior experience and adapt to new tasks
                without
                task-specific training data. Humans effortlessly do tasks like pouring tea, cooking dinner, or
                folding clothes. I foresee an "ideal robotic system" to not only mimic humans in complex real world
                tasks, but <a
                    href="https://medium.com/codex/lee-sedol-vs-alphago-how-googles-a-i-machine-beat-the-18-times-world-go-champion-214ffae72fbd">out-perform
                    them</a>.<br><br> -->

                    <!-- I aim to work towards the following directions:<br>
                        <a>1.</a> Develop scalable algorithms to train end-to-end policies on offline data and 
                        fine-tune them across real-world tasks and embodiments<br>
                        <a>2.</a> Create reliable agents capable of envisioning goals and out-performing humans in complex real-world scenarios. <br>
                        <a>2.</a> Study the pros and cons of current approaches to understand what contributes to generalized robot intelligence.<br>
                        <a>3.</a> Deploy versatile robots to aid humans in need, perform household tasks, and function in hazardous environments. -->

                    <!-- To mitigate the dependency on training data, 
                        I am mainly interested in developing generalist agents that can learn from prior experience and <a>promptly adapt to novel tasks and environmental 
                        constraints</a>, relying primarily on <a>real-time observations</a> during inference. The ultimate objective is to create 
                        <a>versatile robotic agents</a> capable of aiding humans in need, executing a diverse set of tasks, and functioning in 
                        hazardous environments. <br><br> -->

                <p>
                    Email: <a href="mailto:anshshahresearch@gmail.com">anshshahresearch@gmail.com</a> / <a
                        href="mailto:anshshah3009@gmail.com">anshshah3009@gmail.com</a> <br>
                </p>
            </div>
            <div style="clear: both;"></div>
        </div>
        <h1 style="line-height: 0;">Highlights</h1>
        <p style="margin-left: 30px;">(Scroll right to view more; Click for details)</p>
        <!-- <div class="section recent-work">
            <div class="slider">
                <a href="https://www.google.com"><img src="data/projects/obstacle_avoidance_drone_fast.gif"></a>
            </div>
        </div> -->

        <div hidden="hidden">
            <script type="text/javascript" id="clustrmaps"
                src="//clustrmaps.com/map_v2.js?d=dySj_P0p0xWfW1-ictpqnnjw0bJfpblnEo6MTLEstoM&cl=ffffff&w=a"></script>
        </div>

        <div class="divider"></div>
        <div class="section">
            <h1>Timeline</h1>
            <p>
            <ul>
                <li>[ <i>June 2023</i> ] Started as a Research Fellow at <a href="https://robotics.iiit.ac.in/">Robotics
                        Research Center</a>, IIIT Hyderabad under the guidance of
                    <a href="https://scholar.google.co.in/citations?hl=en&user=QDuPGHwAAAAJ&view_op=list_works">Prof.
                        Madhava Krishna</a>.
                </li>
                <li>[ <i>June 2023</i> ] Graduated from <a href="https://www.bits-pilani.ac.in/pilani">BITS Pilani</a>
                    with an <a href="https://www.bits-pilani.ac.in/pilani/physics/">M.Sc. in Physics</a> and a
                    <a href="https://www.bits-pilani.ac.in/pilani/mechanical-engineering/">B.E. in Mechanical
                        Engineering</a>.
                </li>
                <li>[ <i>May 2023</i> ] Defended my off-campus bachelor's thesis on <b>Multi-Agent SLAM</b> for drones,
                    conducted at RRC, IIIT Hyderabad, under the supervision of Prof. Madhav Krishna (IIIT Hyderabad) and
                    <a href="https://www.bits-pilani.ac.in/pilani/amit-rajnarayan-singh/">Prof. Amit Singh (BITS
                        Pilani)</a>.
                </li>
                <!-- <li>
                    [ <i>July 2022</i> ] Interned as a Full Stack Developer at <a
                        href="https://www.maybank.com/en/index.page">MBB Labs-Maybank</a>, Bangalore, for a semester.
                    Tech-Stack: Spring Boot and React.js
                </li> -->
                <li>[ <i>Nov 2021</i> ] Won a Silver Medal at <a href="https://www.uphysicsc.com/">The 2021
                        University Physics Competition</a>.
                </li>
                <li>[ <i>2020</i> ] <a href="https://www.bitsaa.org/">BITSAA</a> approved funding of
                    approximately <b>$25,000</b> for <a href="https://bitsrobocon.github.io/">TEAM BITS ROBOCON's</a>
                    Autonomous Drone and Quadruped projects. Although progress was significantly delayed by the COVID-19
                    pandemic, the projects are now being continued by the team's junior members.
                </li>
                <li>[ <i>2019</i> ] Joined <a href="https://bitsrobocon.github.io/">TEAM BITS ROBOCON</a> as a freshmen,
                    working on quadruped, micromouse and drones; served as Treasurer for 2020-21.
                </li>
            </ul>
            </p>
            <div style="clear: both;"></div>
        </div>

        <div class="divider"></div>

        <div class="section research">
            <h1 style="line-height: 0;">Publications</h1>
            <p style="margin-left: 30px;">* Denotes equal contribution</p>
            <br>
            <!-- <h3><div id="repBtn"><a href="javascript:showRep()">Representative</a></div>&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp;&nbsp;<div id="showAllBtn"><a href="javascript:hideRep()">See All Publications</a></div></h3> -->

            <div class="research-proj">
                <a href="http://arxiv.org/abs/2411.10886" class="research-thumb">
                    <img src="data/projects/MetricGold/MetricGold_main.jpg" alt="" />
                </a>
                <a href="" class="research-proj-title"> MetricGold: Repurposing Diffusion-Based Image Generators for
                    Metric Depth Estimation
                </a>
                <p> <strong>Ansh Shah</strong>, K. Madhava Krishna<br>
                    <a href="http://arxiv.org/abs/2411.10886">[Arxiv]</a>
                <p>This paper explores an approach for monocular metric depth estimation that utilizes generative
                    diffusion models and a log-scaled metric depth representation, achieving sharper and more accurate
                    metric depth predictions across diverse scenes through synthetic data training.</p>
                </p>
                <p> <br> </p>
            </div>

        </div>

        <!-- <br> -->

        <div class="divider"></div>

        <div class="section">
            <h1 style="line-height: 0;">Projects</h1>
            <p style="margin-left: 30px;">(Click on project to view more)</p>
            <br>

            <h3>Major Projects</h3>
            <div class="research-proj">

            </div>

            <div class="research-proj">
                <a href="https://github.com/AnshShah3009/Deep-Koopman-with-Control-for-Drone-Dynamics/"
                    class="research-thumb">
                    <img src="data/projects/Koopman/Koopman_MPC.png" alt="DeepKoopman with Control" />
                </a>
                <a href="https://github.com/AnshShah3009/Deep-Koopman-with-Control-for-Drone-Dynamics/"
                    class="research-proj-title"> Koopman Theory in Deep Learning for Linearizing Drone Dynamics </a>
                <p> Bhanu Teja*, <strong>Ansh Shah*</strong>, <a href="https://devapi016.github.io/">Mihir
                        Ungarala*</a>, <a href="https://tuit.ut.ee/en/content/arun-kumar-singh">Prof Arun Singh</a>, Prof K Madhava Krishna<br>
                        <i>Robotics Research Center, IIIT Hyderabad</i> <br>
                </p>
                <p> Can dynamics linearisation help in computationally cheaper and faster control of drones? We explore
                    the idea of using Koopman theory
                    to linearise the dynamics of a drone and then use a LinearMPC to control it. </p>
                <p> <br> </p>
            </div>

            <div class="research-proj">
                <a href="" class="research-thumb">
                    <img src="data/projects/Rearrange/rearranged.drawio.png" alt="" />
                </a>
                <a href="" class="research-proj-title">Object Associtaion in rearranged scenes for change detection and
                    loop closure registration with pairwise geometric consistency</a>
                <p> <strong>Ansh Shah*</strong>, Aneesh Chavan*, Sarthak Chittawar, <a href="https://krrish94.github.io/"></a>Dr. Krishna Murthy , <a href="https://www.cse.iitd.ac.in/~chetan/">Prof Chetan Arora</a>, Prof K Madhava Krishna<br>
                    <i>Robotics Research Center, IIIT Hyderabad</i> <br>
                </p>
                <p>An Embodied agent in a household setting has to localise itself in rearranged indoor spaces. Relying
                    on normal descriptors can be tricky as small feature rich objects can get rearranges. To mitigate
                    this problem we explored using object instance based localisation.</p>
                <p> <br> </p>
            </div>

            <div class="research-proj">
                <a href="https://github.com/AnshShah3009/Multi-Agent-Robust-PGO" class="research-thumb">
                    <img src="data/projects/Mult_Agent_SLAM/multi_agent_slam.png" alt="Multi-Agent SLAM" />
                </a>
                <a href="https://github.com/AnshShah3009/Multi-Agent-Robust-PGO" class="research-proj-title">
                    Multi-Agent SLAM</a>
                <p> Bhanu Teja*, <strong>Ansh Shah*</strong>, <a href="https://devapi016.github.io/">Mihir
                        Ungarala*</a>, Prof Amit Singh, Prof K Madhava Krishna<br>
                        <i>Robotics Research Center, IIIT Hyderabad | BITS Pilani</i> <br>
                </p>
                <p> <br> </p>
            </div>

            <div class="research-proj">
                <a href="https://github.com/AnshShah3009/AutonomousDrone" class="research-thumb">
                    <img src="data/projects/Drones/Drone.jpg" alt="" />
                </a>
                <a href="https://github.com/AnshShah3009/AutonomousDrone" class="research-proj-title"> Autonomous Drone
                </a>
                <p> <strong>Ansh Shah</strong>, Nidheesh Jain, Nikhil Agarwal<br>
                    <i>Team BITS Robocon</i> <br>
                    <a href="https://github.com/AnshShah3009/AutonomousDrone">Github</a>
                </p>
                <p> <br> </p>
            </div>

            <h3>Mini Projects</h3>

            <!-- <div class="research-proj">
                <a href="" class="research-thumb">
                    <img src="data/projects/DDPM vs Stacked Operator/DDPM vs Stacked Operator.jpeg"
                        alt="DDPM vs Stacked Operator" />
                </a>
                <a href="" class="research-proj-title">Stacked Iterative Operator vs DDPM</a>
                <p> <strong>Ansh Shah</strong> <br>
                    Is diffusion just a regularized version of the stacked iterative operator? If Any
                    destructive forward process can be learned as a reverse process and give similar results? Shown in
                    the paper Cold Diffusion, then what is the significance for the DDPM formulation.
                </p>
                <p> <br> </p>
            </div> -->

            <div class="research-proj">
                <a href="https://github.com/AnshShah3009/Micromouse" class="research-thumb">
                    <img src="data/projects/Micromouse/Micromouse.jpg" alt="" />
                </a>
                <a href="https://github.com/AnshShah3009/Micromouse" class="research-proj-title"> Micromoue </a>
                <p> <strong>Ansh Shah</strong>, Samyak Sahu<br>
                    <i>Team BITS Robocon</i> <br>
                    <a href="https://github.com/AnshShah3009/Micromouse">Github</a>
                </p>
                <p> <br> </p>
            </div>

            <div class="research-proj">
                <a href="https://github.com/AnshShah3009/Cronus" class="research-thumb">
                    <img src="data/projects/Cronus/cronus_design.jpg" alt="" />
                </a>
                <a href="https://github.com/AnshShah3009/Cronus" class="research-proj-title">CRONUS: A Quadrupedal + Holonomic Drive surveillance bot</a>
                <p> Ayush Agarwal, <strong>Ansh Shah</strong>, Atharv Arora, Ananya Khandelwal<br>
                    <i>BITS Pilani</i> <br>
                    <a href="https://github.com/AnshShah3009/Cronus">Github</a>
                </p>
                <p> <br> </p>
            </div>
        </div>

        <div class="divider"></div>

        <div class="section teaching">
            <h1>Teaching</h1>
            <ul>
                <li>
                    In 2024, I took lectures for the <u>RRC Summer School 2024</u>:
                    the first on <u>ICP SLAM & Graph Based SLAM</u>, second on <u>CNN, RNN and Transformer
                        Architecture</u>.
                </li>
                <li>
                    I served as a lecturer for the <u>Mobile Robotics 2023</u> course at <u>IIIT
                        Hyderabad</u>, where I took three lectures: the first on <u>Simultaneous Localization and
                        Mapping (SLAM)</u>, followed by
                    <u>Graph-Based SLAM</u>, and a coding demonstration on pose graph optimization and Landmark SLAM
                    with GTSAM. For details, see the <a href="https://github.com/AnshShah3009/gtsam_tutorials"
                        target="_blank">code</a> and the
                    <a href="https://hirohamada.notion.site/Graph-Based-SLAM-6e550b19ebff41b9a8550b9c4442d742"
                        target="_blank">blog post</a>. This was part of my role as a Research Fellow at RRC.
                </li>
                <li>
                    During my tenure at <a href="https://bitsrobocon.github.io/projects">Team BITS Robocon</a>, I
                    mentored junior team members in tasks related to mechanics, design and programming. Additionally, I
                    conducted interviews to assess potential candidates interested in joining the team.
                </li>
            </ul>
        </div>


        <div class="divider"></div>

        <br>

        <h2>Template borrowed from <a href="https://shurans.github.io/">Shuran Song</a>'s personal page</h2>

        <br><br>

    </div>
</body>

</html>
